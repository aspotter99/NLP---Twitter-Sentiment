{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adamroth/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.probability import FreqDist\n",
    "import re\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import *\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/adamroth/Documents/flat_fe_work/mod4/week13/NLP---Twitter-Sentiment/notebooks/AR_notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../../data/judge-1377884607_tweet_product_company.csv', encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1393</td>\n",
       "      <td>÷¼ No fear, no envy, no meanness, no lies, no...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4243</td>\n",
       "      <td>Hmm....only 9? #SXSW right-brain #mwrc11 left-...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>562</td>\n",
       "      <td>When will Google Circles launch? {link} &amp;quot;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1429</td>\n",
       "      <td>SXSW 2011: Novelty of iPad news apps fades fas...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2741</td>\n",
       "      <td>Brains are to zombies like content is to googl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2441</td>\n",
       "      <td>Google and Bing meet at #SXSW after their love...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8913</td>\n",
       "      <td>Time to switch to @mention on my iPhone so I c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3975</td>\n",
       "      <td>Great talk by @mention from @mention about gam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5155</td>\n",
       "      <td>RT @mention @mention Who said you won't be abl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2506</td>\n",
       "      <td>The forbidden apple has been spoiled! Long liv...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>403</td>\n",
       "      <td>Trying to collaborate on #sxsw events with a f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5669</td>\n",
       "      <td>RT @mention Developers Learn About Mobile Acce...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8919</td>\n",
       "      <td>Current Twitter feed: devastation in Japan, pa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8031</td>\n",
       "      <td>Today is so big, me and my stomach flu can har...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8831</td>\n",
       "      <td>Geez #sxsw people are eating this up. Another ...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "1393  ÷¼ No fear, no envy, no meanness, no lies, no...   \n",
       "4243  Hmm....only 9? #SXSW right-brain #mwrc11 left-...   \n",
       "562   When will Google Circles launch? {link} &quot;...   \n",
       "1429  SXSW 2011: Novelty of iPad news apps fades fas...   \n",
       "2741  Brains are to zombies like content is to googl...   \n",
       "2441  Google and Bing meet at #SXSW after their love...   \n",
       "8913  Time to switch to @mention on my iPhone so I c...   \n",
       "3975  Great talk by @mention from @mention about gam...   \n",
       "5155  RT @mention @mention Who said you won't be abl...   \n",
       "2506  The forbidden apple has been spoiled! Long liv...   \n",
       "403   Trying to collaborate on #sxsw events with a f...   \n",
       "5669  RT @mention Developers Learn About Mobile Acce...   \n",
       "8919  Current Twitter feed: devastation in Japan, pa...   \n",
       "8031  Today is so big, me and my stomach flu can har...   \n",
       "8831  Geez #sxsw people are eating this up. Another ...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "1393                             NaN   \n",
       "4243                            iPad   \n",
       "562                              NaN   \n",
       "1429              iPad or iPhone App   \n",
       "2741                             NaN   \n",
       "2441                          Google   \n",
       "8913                             NaN   \n",
       "3975                             NaN   \n",
       "5155                             NaN   \n",
       "2506                           Apple   \n",
       "403                              NaN   \n",
       "5669                             NaN   \n",
       "8919                             NaN   \n",
       "8031                             NaN   \n",
       "8831                            iPad   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "1393                 No emotion toward brand or product  \n",
       "4243                                   Positive emotion  \n",
       "562                  No emotion toward brand or product  \n",
       "1429                                   Negative emotion  \n",
       "2741                 No emotion toward brand or product  \n",
       "2441                                   Negative emotion  \n",
       "8913                 No emotion toward brand or product  \n",
       "3975                 No emotion toward brand or product  \n",
       "5155                 No emotion toward brand or product  \n",
       "2506                                   Negative emotion  \n",
       "403                  No emotion toward brand or product  \n",
       "5669                 No emotion toward brand or product  \n",
       "8919                 No emotion toward brand or product  \n",
       "8031                 No emotion toward brand or product  \n",
       "8831                                       I can't tell  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5191    Other Google product or service\n",
       "2291                                NaN\n",
       "4521                                NaN\n",
       "1546                                NaN\n",
       "6162                                NaN\n",
       "3854                                NaN\n",
       "3465                                NaN\n",
       "2127                              Apple\n",
       "5012                                NaN\n",
       "3554                              Apple\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['emotion_in_tweet_is_directed_at'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['iPhone', 'iPad or iPhone App', 'iPad', 'Google', nan, 'Android',\n",
       "       'Apple', 'Android App', 'Other Google product or service',\n",
       "       'Other Apple product or service'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['emotion_in_tweet_is_directed_at'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9088</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9089</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9090</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9091</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9092</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9093 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_text  emotion_in_tweet_is_directed_at  \\\n",
       "0          False                            False   \n",
       "1          False                            False   \n",
       "2          False                            False   \n",
       "3          False                            False   \n",
       "4          False                            False   \n",
       "...          ...                              ...   \n",
       "9088       False                            False   \n",
       "9089       False                             True   \n",
       "9090       False                             True   \n",
       "9091       False                             True   \n",
       "9092       False                             True   \n",
       "\n",
       "      is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                                 False   \n",
       "1                                                 False   \n",
       "2                                                 False   \n",
       "3                                                 False   \n",
       "4                                                 False   \n",
       "...                                                 ...   \n",
       "9088                                              False   \n",
       "9089                                              False   \n",
       "9090                                              False   \n",
       "9091                                              False   \n",
       "9092                                              False   \n",
       "\n",
       "[9093 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                                            object\n",
       "emotion_in_tweet_is_directed_at                       object\n",
       "is_there_an_emotion_directed_at_a_brand_or_product    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPad                               946\n",
       "Apple                              661\n",
       "iPad or iPhone App                 470\n",
       "Google                             430\n",
       "iPhone                             297\n",
       "Other Google product or service    293\n",
       "Android App                         81\n",
       "Android                             78\n",
       "Other Apple product or service      35\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['emotion_in_tweet_is_directed_at'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lots of nan's in this column, shouldn't matter while training model though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5389\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not many negatives, might need to mess with that, could use something like smote, might remove all from 'I cant tell'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f6ec24981925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "raw_data.iloc[i].tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.@wesley83',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " '3G',\n",
       " 'iPhone.',\n",
       " 'After',\n",
       " '3',\n",
       " 'hrs',\n",
       " 'tweeting',\n",
       " 'at',\n",
       " '#RISE_Austin,',\n",
       " 'it',\n",
       " 'was',\n",
       " 'dead!',\n",
       " 'I',\n",
       " 'need',\n",
       " 'to',\n",
       " 'upgrade.',\n",
       " 'Plugin',\n",
       " 'stations',\n",
       " 'at',\n",
       " '#SXSW.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.iloc[0].tweet_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list = raw_data.iloc[0].tweet_text.split()\n",
    "type(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_text', 'emotion_in_tweet_is_directed_at',\n",
       "       'is_there_an_emotion_directed_at_a_brand_or_product', 'split_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = raw_data\n",
    "df['split_text'] = 0\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@teachntech00 New iPad Apps For #SpeechTherapy And Communication Are Showcased At The #SXSW Conference http://ht.ly/49n4M #iear #edchat #asd'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['tweet_text'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamroth/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/adamroth/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(raw_data)):\n",
    "    text = raw_data['tweet_text'][i]\n",
    "    split_text = str(text).split()\n",
    "    df['split_text'][i] = split_text\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@sxtxstate',\n",
       " 'great',\n",
       " 'stuff',\n",
       " 'on',\n",
       " 'Fri',\n",
       " '#SXSW:',\n",
       " 'Marissa',\n",
       " 'Mayer',\n",
       " '(Google),',\n",
       " 'Tim',\n",
       " \"O'Reilly\",\n",
       " '(tech',\n",
       " 'books/conferences)',\n",
       " '&amp;',\n",
       " 'Matt',\n",
       " 'Mullenweg',\n",
       " '(Wordpress)']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['split_text'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "punctuation = string.punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_punct(string):\n",
    "\n",
    "    clean_text_list = [''.join(ch for ch in s if ch not in punctuation) for s in string]\n",
    "    \n",
    "    #clean_text = \"\"\n",
    "    \n",
    "    #return (clean_text.join(clean_text_list))\n",
    "    return clean_text_list\n",
    "#cleans up punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 's', 'x', 't', 'x', 's', 't', 'a', 't', 'e']\n"
     ]
    }
   ],
   "source": [
    "string = \"@sxtxstate\"\n",
    "clean_punct(string)\n",
    "print(clean_punct(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sxtxstate',\n",
       " 'great',\n",
       " 'stuff',\n",
       " 'on',\n",
       " 'Fri',\n",
       " 'SXSW',\n",
       " 'Marissa',\n",
       " 'Mayer',\n",
       " 'Google',\n",
       " 'Tim',\n",
       " 'OReilly',\n",
       " 'tech',\n",
       " 'booksconferences',\n",
       " 'amp',\n",
       " 'Matt',\n",
       " 'Mullenweg',\n",
       " 'Wordpress']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_punct(df['split_text'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_column(df['column']):\n",
    "#     for i in range(0, len(df)):\n",
    "#         thing = df['column'][i]\n",
    "#         clean_string = str(thing)\n",
    "#         return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_punct'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamroth/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(df)):\n",
    "    has_punct = df['split_text'][i]\n",
    "    no_punct = clean_punct(has_punct)\n",
    "    df['no_punct'][i] = no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jessedee',\n",
       " 'Know',\n",
       " 'about',\n",
       " 'fludapp',\n",
       " '',\n",
       " 'Awesome',\n",
       " 'iPadiPhone',\n",
       " 'app',\n",
       " 'that',\n",
       " 'youll',\n",
       " 'likely',\n",
       " 'appreciate',\n",
       " 'for',\n",
       " 'its',\n",
       " 'design',\n",
       " 'Also',\n",
       " 'theyre',\n",
       " 'giving',\n",
       " 'free',\n",
       " 'Ts',\n",
       " 'at',\n",
       " 'SXSW']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['no_punct'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: clean, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean'] = 0\n",
    "df['clean'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamroth/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(df)):\n",
    "    a = df['no_punct'][i]\n",
    "    now_lower = str(a).lower()\n",
    "    df['clean'][i] = now_lower\n",
    "#I'm a dumb dumb who forgot that df.apply is a thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['wesley83', 'i', 'have', 'a', '3g', 'iphone',...\n",
       "1    ['jessedee', 'know', 'about', 'fludapp', '', '...\n",
       "2    ['swonderlin', 'can', 'not', 'wait', 'for', 'i...\n",
       "3    ['sxsw', 'i', 'hope', 'this', 'years', 'festiv...\n",
       "4    ['sxtxstate', 'great', 'stuff', 'on', 'fri', '...\n",
       "Name: clean, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9093\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>split_text</th>\n",
       "      <th>no_punct</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8631</td>\n",
       "      <td>#SocialNetworks: #Google noch heute mit #Circl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I can't tell</td>\n",
       "      <td>[#SocialNetworks:, #Google, noch, heute, mit, ...</td>\n",
       "      <td>[SocialNetworks, Google, noch, heute, mit, Cir...</td>\n",
       "      <td>['socialnetworks', 'google', 'noch', 'heute', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>New buzz? &amp;quot;@mention Google to Launch Majo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[New, buzz?, &amp;quot;@mention, Google, to, Launc...</td>\n",
       "      <td>[New, buzz, quotmention, Google, to, Launch, M...</td>\n",
       "      <td>['new', 'buzz', 'quotmention', 'google', 'to',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>Temporary Pop Shop by #Apple at #SXSW and Nice...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[Temporary, Pop, Shop, by, #Apple, at, #SXSW, ...</td>\n",
       "      <td>[Temporary, Pop, Shop, by, Apple, at, SXSW, an...</td>\n",
       "      <td>['temporary', 'pop', 'shop', 'by', 'apple', 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4502</td>\n",
       "      <td>Anyone find the makeshift #Apple store at #SXS...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[Anyone, find, the, makeshift, #Apple, store, ...</td>\n",
       "      <td>[Anyone, find, the, makeshift, Apple, store, a...</td>\n",
       "      <td>['anyone', 'find', 'the', 'makeshift', 'apple'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5427</td>\n",
       "      <td>RT @mention Apple heads to SXSW, sets up tempo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[RT, @mention, Apple, heads, to, SXSW,, sets, ...</td>\n",
       "      <td>[RT, mention, Apple, heads, to, SXSW, sets, up...</td>\n",
       "      <td>['rt', 'mention', 'apple', 'heads', 'to', 'sxs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1936</td>\n",
       "      <td>I just realized my iPhone's gonna go nuts with...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I can't tell</td>\n",
       "      <td>[I, just, realized, my, iPhone's, gonna, go, n...</td>\n",
       "      <td>[I, just, realized, my, iPhones, gonna, go, nu...</td>\n",
       "      <td>['i', 'just', 'realized', 'my', 'iphones', 'go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8378</td>\n",
       "      <td>@mention tell @mention to give out gummy worms...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[@mention, tell, @mention, to, give, out, gumm...</td>\n",
       "      <td>[mention, tell, mention, to, give, out, gummy,...</td>\n",
       "      <td>['mention', 'tell', 'mention', 'to', 'give', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8462</td>\n",
       "      <td>&amp;quot;If there's one thing SXSW is good for, i...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[&amp;quot;If, there's, one, thing, SXSW, is, good...</td>\n",
       "      <td>[quotIf, theres, one, thing, SXSW, is, good, f...</td>\n",
       "      <td>['quotif', 'theres', 'one', 'thing', 'sxsw', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5330</td>\n",
       "      <td>RT @mention #Want: Micro USB charger for Samsu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[RT, @mention, #Want:, Micro, USB, charger, fo...</td>\n",
       "      <td>[RT, mention, Want, Micro, USB, charger, for, ...</td>\n",
       "      <td>['rt', 'mention', 'want', 'micro', 'usb', 'cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5978</td>\n",
       "      <td>RT @mention Heard about Apple's pop-up store i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[RT, @mention, Heard, about, Apple's, pop-up, ...</td>\n",
       "      <td>[RT, mention, Heard, about, Apples, popup, sto...</td>\n",
       "      <td>['rt', 'mention', 'heard', 'about', 'apples', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "8631  #SocialNetworks: #Google noch heute mit #Circl...   \n",
       "100   New buzz? &quot;@mention Google to Launch Majo...   \n",
       "1010  Temporary Pop Shop by #Apple at #SXSW and Nice...   \n",
       "4502  Anyone find the makeshift #Apple store at #SXS...   \n",
       "5427  RT @mention Apple heads to SXSW, sets up tempo...   \n",
       "1936  I just realized my iPhone's gonna go nuts with...   \n",
       "8378  @mention tell @mention to give out gummy worms...   \n",
       "8462  &quot;If there's one thing SXSW is good for, i...   \n",
       "5330  RT @mention #Want: Micro USB charger for Samsu...   \n",
       "5978  RT @mention Heard about Apple's pop-up store i...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "8631                             NaN   \n",
       "100                              NaN   \n",
       "1010                             NaN   \n",
       "4502                           Apple   \n",
       "5427                             NaN   \n",
       "1936                             NaN   \n",
       "8378                             NaN   \n",
       "8462                           Apple   \n",
       "5330                             NaN   \n",
       "5978                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "8631                                       I can't tell   \n",
       "100                  No emotion toward brand or product   \n",
       "1010                                   Positive emotion   \n",
       "4502                                   Positive emotion   \n",
       "5427                 No emotion toward brand or product   \n",
       "1936                                       I can't tell   \n",
       "8378                 No emotion toward brand or product   \n",
       "8462                                   Positive emotion   \n",
       "5330                 No emotion toward brand or product   \n",
       "5978                 No emotion toward brand or product   \n",
       "\n",
       "                                             split_text  \\\n",
       "8631  [#SocialNetworks:, #Google, noch, heute, mit, ...   \n",
       "100   [New, buzz?, &quot;@mention, Google, to, Launc...   \n",
       "1010  [Temporary, Pop, Shop, by, #Apple, at, #SXSW, ...   \n",
       "4502  [Anyone, find, the, makeshift, #Apple, store, ...   \n",
       "5427  [RT, @mention, Apple, heads, to, SXSW,, sets, ...   \n",
       "1936  [I, just, realized, my, iPhone's, gonna, go, n...   \n",
       "8378  [@mention, tell, @mention, to, give, out, gumm...   \n",
       "8462  [&quot;If, there's, one, thing, SXSW, is, good...   \n",
       "5330  [RT, @mention, #Want:, Micro, USB, charger, fo...   \n",
       "5978  [RT, @mention, Heard, about, Apple's, pop-up, ...   \n",
       "\n",
       "                                               no_punct  \\\n",
       "8631  [SocialNetworks, Google, noch, heute, mit, Cir...   \n",
       "100   [New, buzz, quotmention, Google, to, Launch, M...   \n",
       "1010  [Temporary, Pop, Shop, by, Apple, at, SXSW, an...   \n",
       "4502  [Anyone, find, the, makeshift, Apple, store, a...   \n",
       "5427  [RT, mention, Apple, heads, to, SXSW, sets, up...   \n",
       "1936  [I, just, realized, my, iPhones, gonna, go, nu...   \n",
       "8378  [mention, tell, mention, to, give, out, gummy,...   \n",
       "8462  [quotIf, theres, one, thing, SXSW, is, good, f...   \n",
       "5330  [RT, mention, Want, Micro, USB, charger, for, ...   \n",
       "5978  [RT, mention, Heard, about, Apples, popup, sto...   \n",
       "\n",
       "                                                  clean  \n",
       "8631  ['socialnetworks', 'google', 'noch', 'heute', ...  \n",
       "100   ['new', 'buzz', 'quotmention', 'google', 'to',...  \n",
       "1010  ['temporary', 'pop', 'shop', 'by', 'apple', 'a...  \n",
       "4502  ['anyone', 'find', 'the', 'makeshift', 'apple'...  \n",
       "5427  ['rt', 'mention', 'apple', 'heads', 'to', 'sxs...  \n",
       "1936  ['i', 'just', 'realized', 'my', 'iphones', 'go...  \n",
       "8378  ['mention', 'tell', 'mention', 'to', 'give', '...  \n",
       "8462  ['quotif', 'theres', 'one', 'thing', 'sxsw', '...  \n",
       "5330  ['rt', 'mention', 'want', 'micro', 'usb', 'cha...  \n",
       "5978  ['rt', 'mention', 'heard', 'about', 'apples', ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_preparer(doc, stop_words=sw):\n",
    "    '''\n",
    "    \n",
    "    :param doc: a document from the corpus \n",
    "    :return: a document string with words which have been \n",
    "            lemmatized, \n",
    "            parsed for stopwords, \n",
    "            made lowercase,\n",
    "            and stripped of punctuation and numbers.\n",
    "    '''\n",
    "    \n",
    "    regex_token = RegexpTokenizer(r\"([a-zA-Z]+(?:’[a-z]+)?)\")\n",
    "    doc = regex_token.tokenize(doc)\n",
    "    doc = [word.lower() for word in doc]\n",
    "    doc = [word for word in doc if word not in stop_words]\n",
    "    doc = pos_tag(doc)\n",
    "    doc = [(word[0], get_wordnet_pos(word[1])) for word in doc]\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    doc = [lemmatizer.lemmatize(word[0], word[1]) for word in doc]\n",
    "    return ' '.join(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'open',\n",
       " 'line',\n",
       " 'one',\n",
       " 'amp',\n",
       " 'come',\n",
       " 'win',\n",
       " 'like',\n",
       " 'via',\n",
       " 'launch',\n",
       " 'cool',\n",
       " 'day',\n",
       " 'time',\n",
       " 'temporary',\n",
       " 'use',\n",
       " 'apps',\n",
       " 'love',\n",
       " 'downtown',\n",
       " 'free',\n",
       " 'great']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_sw = pd.read_csv('../asp_notebooks/apl_prd_custom_stop.csv')\n",
    "extra_sw = list(extra_sw['tweet_text'])\n",
    "extra_sw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'go',\n",
       " 'open',\n",
       " 'line',\n",
       " 'one',\n",
       " 'amp',\n",
       " 'come',\n",
       " 'win',\n",
       " 'like',\n",
       " 'via',\n",
       " 'launch',\n",
       " 'cool',\n",
       " 'day',\n",
       " 'time',\n",
       " 'temporary',\n",
       " 'use',\n",
       " 'apps',\n",
       " 'love',\n",
       " 'downtown',\n",
       " 'free',\n",
       " 'great']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw = sw + extra_sw\n",
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_sw(df):\n",
    "#     for i in range(0, len(df)):\n",
    "#         for word in df['clean'][i]:\n",
    "#             if word in sw:\n",
    "#                 word.remove(sw)\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['wesley83', 'i', 'have', 'a', '3g', 'iphone',...\n",
       "1    ['jessedee', 'know', 'about', 'fludapp', '', '...\n",
       "2    ['swonderlin', 'can', 'not', 'wait', 'for', 'i...\n",
       "3    ['sxsw', 'i', 'hope', 'this', 'years', 'festiv...\n",
       "4    ['sxtxstate', 'great', 'stuff', 'on', 'fri', '...\n",
       "5    ['teachntech00', 'new', 'ipad', 'apps', 'for',...\n",
       "6                                              ['nan']\n",
       "7    ['sxsw', 'is', 'just', 'starting', 'ctia', 'is...\n",
       "8    ['beautifully', 'smart', 'and', 'simple', 'ide...\n",
       "9    ['counting', 'down', 'the', 'days', 'to', 'sxs...\n",
       "Name: clean, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean'] = [' '.join([a for a in x.split() if a not in sw]) for x in df['clean']]\n",
    "#shouldn't that work?\n",
    "df['clean'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5389\n"
     ]
    }
   ],
   "source": [
    "df_no_emo = df[df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'No emotion toward brand or product']\n",
    "print(len(df_no_emo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg = df[df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Negative emotion']\n",
    "len(df_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2978"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos = df[df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Positive emotion']\n",
    "len(df_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90     ['thanks', 'to', 'mention', 'for', 'publishing...\n",
       "102    ['\\x89ûïmention', 'quotapple', 'has', 'opened'...\n",
       "237    ['just', 'what', 'america', 'needs', 'rt', 'me...\n",
       "341    ['the', 'queue', 'at', 'the', 'apple', 'store'...\n",
       "368    ['hope', 'its', 'better', 'than', 'wave', 'rt'...\n",
       "Name: clean, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unclear = df[df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'I can\\'t tell']\n",
    "print(len(df_unclear))\n",
    "df_unclear['clean'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_pos.clean.astype('str')\n",
    "# y = df.is_there_an_emotion_directed_at_a_brand_or_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WordListCorpusReader in '/Users/adamroth/nltk_data/corpora/stopwords'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
